import os
import pandas as pd
import gc
import folder_paths
from huggingface_hub import hf_hub_download

# ÂÖ®Â±ÄÂèòÈáèÂ≠òÂÇ® DataFrame
_DANBOORU_DB = None
_IS_LOADING = False

class DanbooruTagsGenerator:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "operation": (["Load & Generate", "Unload Memory"], {"default": "Load & Generate"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "min_score": ("INT", {"default": 20, "min": 0, "max": 10000}),
                "allowed_ratings": ("STRING", {"default": "g, s, q, e", "placeholder": "g, s, q, e"}),
                "include_tags": ("STRING", {"multiline": True, "default": "1girl", "placeholder": "ÂøÖÂê´Ê†áÁ≠æ"}),
                "exclude_tags": ("STRING", {"multiline": True, "default": "comic, monochrome", "placeholder": "ÊéíÈô§Ê†áÁ≠æ"}),
            },
            "optional": {
                "hf_repo_id": ("STRING", {"default": "deepghs/danbooru2024"}),
                "hf_filename": ("STRING", {"default": "metadata.parquet"}),
                "hf_token": ("STRING", {"default": "", "placeholder": "Optional: HuggingFace Token"}),
            }
        }

    RETURN_TYPES = ("STRING", "INT", "STRING", "STRING")
    RETURN_NAMES = ("final_prompt", "score", "danbooru_url", "rating")
    FUNCTION = "process"
    CATEGORY = "Danbooru Tlant"

    def unload_memory(self):
        global _DANBOORU_DB
        if _DANBOORU_DB is not None:
            print("üßπ [Danbooru Tlant] Ê≠£Âú®Âç∏ËΩΩÊï∞ÊçÆÂπ∂ÈáäÊîæÂÜÖÂ≠ò...")
            del _DANBOORU_DB
            _DANBOORU_DB = None
            gc.collect()
            print("‚úÖ [Danbooru Tlant] ÂÜÖÂ≠òÂ∑≤ÈáäÊîæ„ÄÇ")
        else:
            print("‚ÑπÔ∏è [Danbooru Tlant] ÂÜÖÂ≠ò‰∏≠Ê≤°ÊúâÊï∞ÊçÆÔºåÊó†ÈúÄÂç∏ËΩΩ„ÄÇ")

    def load_dataframe(self, file_path):
        global _DANBOORU_DB, _IS_LOADING
        
        if _DANBOORU_DB is not None:
            return _DANBOORU_DB
        
        if _IS_LOADING:
            raise Exception("Ê≠£Âú®Âä†ËΩΩÊï∞ÊçÆ‰∏≠ÔºåËØ∑Á®çÂêéÂÜçËØï...")

        _IS_LOADING = True
        try:
            print(f"üì¶ [Danbooru Tlant] Ê≠£Âú®Âä†ËΩΩ Parquet: {file_path}")
            
            # 1. ‰∏çÊòæÂºèÊåáÂÆöÂàóÔºåÂÖàËØªÂèñÊâÄÊúâÂàóÁöÑSchemaÔºåÈò≤Ê≠¢'id'‰∏çÂ≠òÂú®ÂØºËá¥Êä•Èîô
            # ‰ΩÜ‰∏∫‰∫ÜÂÜÖÂ≠òÔºåÊàë‰ª¨ËøòÊòØÂæóÁ≠õÈÄâ„ÄÇ
            # ÂÖàÂ∞ùËØïÊ†áÂáÜÂàóÂêç
            columns_to_load = ['tag_string', 'score', 'rating', 'id']
            
            try:
                df = pd.read_parquet(file_path, columns=columns_to_load)
            except Exception as col_err:
                print(f"‚ö†Ô∏è [Danbooru Tlant] ÊåâÊåáÂÆöÂàóÂä†ËΩΩÂ§±Ë¥•ÔºåÂ∞ùËØï‰∏çÊåáÂÆöÂàóÂêçÂä†ËΩΩ (ÂèØËÉΩ ID ÊòØÁ¥¢Âºï)... ÈîôËØØ: {col_err}")
                # Â¶ÇÊûúÂ§±Ë¥•ÔºåÂèØËÉΩÊòØ 'id' Âàó‰∏çÂ≠òÂú®Ôºà‰πüËÆ∏ÂÆÉÊòØ indexÔºâ
                # Êàë‰ª¨Âè™ËØªÊ†∏ÂøÉÂàóÔºå‰∏çËØª id
                fallback_cols = ['tag_string', 'score', 'rating']
                df = pd.read_parquet(file_path, columns=fallback_cols)

            # ÂéªÈô§Á©∫ tag
            df = df.dropna(subset=['tag_string'])
            
            _DANBOORU_DB = df
            
            print(f"‚úÖ [Danbooru Tlant] Êï∞ÊçÆÂä†ËΩΩÂÆåÊØïÔºåÂÖ± {len(df)} Êù°ËÆ∞ÂΩï„ÄÇ")
            print(f"üîç [Debug] ÂΩìÂâçÊï∞ÊçÆÂàóÂêç: {df.columns.tolist()}")
            
            return df
        except Exception as e:
            print(f"‚ùå [Danbooru Tlant] Âä†ËΩΩ DataFrame Â§±Ë¥•: {e}")
            raise e
        finally:
            _IS_LOADING = False

    def process(self, operation, seed, min_score, allowed_ratings, include_tags, exclude_tags, hf_repo_id, hf_filename, hf_token):
        # 1. ÂÜÖÂ≠òÂç∏ËΩΩÈÄªËæë
        if operation == "Unload Memory":
            self.unload_memory()
            return ("", 0, "", "")

        # 2. Ë∑ØÂæÑÂ§ÑÁêÜ
        base_model_dir = os.path.join(folder_paths.base_path, "models")
        danbooru_dir = os.path.join(base_model_dir, "danbooru")
        
        if not os.path.exists(danbooru_dir):
            os.makedirs(danbooru_dir, exist_ok=True)
            
        file_path = os.path.join(danbooru_dir, hf_filename)

        # 3. ‰∏ãËΩΩÈÄªËæë
        if not os.path.exists(file_path):
            print(f"üöÄ [Danbooru Tlant] ÂáÜÂ§á‰∏ãËΩΩ...")
            try:
                token = hf_token.strip() if hf_token.strip() != "" else None
                downloaded_path = hf_hub_download(
                    repo_id=hf_repo_id,
                    filename=hf_filename,
                    repo_type="dataset",
                    local_dir=danbooru_dir,
                    token=token,
                    local_dir_use_symlinks=False 
                )
                file_path = downloaded_path
            except Exception as e:
                error_msg = f"Download Failed: {str(e)}"
                print(f"‚ùå [Danbooru Tlant] {error_msg}")
                return (error_msg, 0, "", "")

        # 4. Âä†ËΩΩÊï∞ÊçÆ
        try:
            df = self.load_dataframe(file_path)
        except Exception as e:
            return (f"Load Error: {str(e)}", 0, "", "")

        # 5. Á≠õÈÄâÈÄªËæë
        target_ratings = [r.strip() for r in allowed_ratings.split(',') if r.strip()]
        if not target_ratings: 
            target_ratings = ['g', 's', 'q', 'e']
        
        filtered = df[df['rating'].isin(target_ratings)]
        filtered = filtered[filtered['score'] >= min_score]

        inc_list = [t.strip() for t in include_tags.replace('\n', ',').split(',') if t.strip()]
        for tag in inc_list:
            filtered = filtered[filtered['tag_string'].str.contains(tag, regex=False)]

        exc_list = [t.strip() for t in exclude_tags.replace('\n', ',').split(',') if t.strip()]
        for tag in exc_list:
            filtered = filtered[~filtered['tag_string'].str.contains(tag, regex=False)]

        # 6. ÈöèÊú∫ÊäΩÂèñ
        count = len(filtered)
        if count == 0:
            print("‚ö†Ô∏è [Danbooru Tlant] Êú™ÊâæÂà∞Á¨¶ÂêàÊù°‰ª∂ÁöÑÂõæÁâá„ÄÇ")
            return ("Tags not found matching criteria", 0, "No URL", "")

        # ‰ΩøÁî® seed
        sample = filtered.sample(n=1, random_state=seed % (2**32)).iloc[0]

        # 7. Â§ÑÁêÜÊï∞ÊçÆ
        # Tag Â§ÑÁêÜ
        raw_tags = sample['tag_string'].split(' ')
        processed_tags = [t.replace('_', ' ') for t in raw_tags if t.strip()]
        final_tags = ", ".join(processed_tags)

        # Ëé∑Âèñ ID Âíå URL (Â¢ûÂä†ÂÅ•Â£ÆÊÄß)
        image_score = int(sample['score'])
        image_rating = str(sample['rating'])
        
        image_id_val = 0 # ÂàùÂßãÂåñÈò≤Ê≠¢ UnboundLocalError
        danbooru_url = ""

        try:
            # Á≠ñÁï•A: Â∞ùËØï‰ªéÂàó‰∏≠Ëé∑Âèñ 'id'
            if 'id' in sample:
                image_id_val = int(sample['id'])
            # Á≠ñÁï•B: Â∞ùËØï‰ªé Index Ëé∑Âèñ (Â¶ÇÊûúÊòØ DataFrame ÁöÑÁ¥¢Âºï)
            elif hasattr(sample, 'name'):
                print(f"‚ÑπÔ∏è [Debug] 'id' ÂàóÊú™ÊâæÂà∞ÔºåÂ∞ùËØï‰ΩøÁî®Á¥¢Âºï: {sample.name}")
                image_id_val = int(sample.name)
            else:
                print("‚ùå [Debug] Êó†Ê≥ïÂú®Ë°åÊï∞ÊçÆ‰∏≠ÊâæÂà∞ ID Êàñ Á¥¢Âºï„ÄÇ")
                image_id_val = 0
            
            if image_id_val > 0:
                danbooru_url = f"https://danbooru.donmai.us/posts/{image_id_val}"
            else:
                danbooru_url = "ID not found"

        except Exception as e:
            print(f"‚ùå ID Logic Error: {e}")
            danbooru_url = "Error generating URL"

        print(f"üéØ [Danbooru Tlant] ÈÄâ‰∏≠ ID: {image_id_val}, Rating: {image_rating}, Score: {image_score}")
        
        return (final_tags, image_score, danbooru_url, image_rating)

NODE_CLASS_MAPPINGS = {
    "DanbooruRandomTagsGeneratorTlant": DanbooruTagsGenerator
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DanbooruRandomTagsGeneratorTlant": "Danbooru Tags Generator (Tlant)"
}